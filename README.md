# Preventing Adversarial Attacks on Machine Learning Models
Projet IA - IASD - Université Paris Dauphine : Abdoulaye DOUCOURE et Frédéric LEITE

<br>
<br>

## Robustness
### [Attack on Linear models](https://neohack22.github.io/iasd.github.io/ROBUST_presentation_1.slides.html#/)
### [Attack on Neural Networks](https://neohack22.github.io/iasd.github.io/)
### [Building robustness](https://neohack22.github.io/iasd.github.io/)

<br>
<br>

## Privacy
### [Basic Approches : K-Anonymity + L-Diversity + T-Closeness](https://neohack22.github.io/iasd.github.io/ROBUST_presentation_2.slides.html)
### [Differential Privacy](https://neohack22.github.io/iasd.github.io/)
### [Case study: Case Study - Health Care dataset](https://neohack22.github.io/iasd.github.io/)
