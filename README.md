# Preventing Adversarial Attacks on Machine Learning Models
Projet IA - IASD - Université Paris Dauphine : Abdoulaye DOUCOURE et Frédéric LEITE

<br>
<br>

## Robustness
### [Attack on Linear models](https://neohack22.github.io/iasd.github.io/ROBUST_presentation_1.slides.html#/)
### [Attack on Neural Networks](https://neohack22.github.io/iasd.github.io/ROBUST_presentation_2.slides.html)
### [Building robustness](https://neohack22.github.io/iasd.github.io/ROBUST_presentation_3.slides.html)

<br>
<br>

## Privacy
### [Basic Approches : K-Anonymity + L-Diversity + T-Closeness](https://neohack22.github.io/iasd.github.io//PRIVACY_Notebook_4_Basic_Approaches_kAnonymity_lDiversity_tCloseness.slides.html)
### [Differential Privacy](https://neohack22.github.io/iasd.github.io/PRIVACY_Notebook_5_Differential_Privacy.slides.html)
### [Case Study - Health Care dataset](https://neohack22.github.io/iasd.github.io/PRIVACY_presentation_6_Case_Study.slides.html)
